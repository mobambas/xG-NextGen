# xGâ€‘NextGen: Improving Expected Goals with AI

**Inspired by the highs and lows I experienced as a lifelong Manchester United supporter during the 2024/25 season**, this repository brings together my passion for football and my expertise in data science to tackle one of the gameâ€™s most controversial metrics: Expected Goals (xG).

---

## ğŸ“– Project Introduction

Conventional xG modelsâ€”built almost exclusively on basic shot location and angleâ€”often misrepresent true scoring probabilities, leaving both fans and analysts frustrated when â€œexpectedâ€ goals donâ€™t materialize on the scoresheet. Having watched Manchester United generate xG north of 2.0 on numerous occasions yet leave Old Trafford emptyâ€‘handed, I set out to diagnose and remedy these blind spots.

**xGâ€‘NextGen** is an endâ€‘toâ€‘end research pipeline that uses stateâ€‘ofâ€‘theâ€‘art machine learning to:

- **Integrate Rich Contextual Features:** defender proximity, goalkeeper positioning, shot velocity, assist type, preâ€‘shot sequences, and match state.  
- **Model Player and Keeper Skill:** hierarchical embeddings capture individual finishing and saving ability, rather than treating all shooters and keepers as interchangeable.  
- **Apply Robust Calibration:** outâ€‘ofâ€‘sample isotonic regression and Platt scaling ensure probabilities align with realâ€‘world outcomes, especially at the extremes.  
- **Adapt Across Leagues and Seasons:** hierarchical Bayesian priors and teamâ€‘season embeddings allow the model to evolve with tactical trends.  

---

## ğŸ“‚ Repository Structure

xGâ€‘NextGen/
â”œâ”€â”€ app.py # Streamlit demo: interactive & batch prediction
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ scripts/ # Utility scripts (JSON loading, freezeâ€‘frame parsing)
â”‚ â””â”€â”€ utils.py
â”œâ”€â”€ notebooks/ # Jupyter notebooks for each pipeline stage
â”‚ â”œâ”€â”€ 01_data_cleaning.ipynb
â”‚ â”œâ”€â”€ 02_feature_eng.ipynb
â”‚ â””â”€â”€ 03_modeling.ipynb
â”œâ”€â”€ data/ # Not tracked (see .gitignore)
â”‚ â”œâ”€â”€ raw/ # StatsBomb JSON downloads
â”‚ â””â”€â”€ processed/ # cleaned CSVs: shots.csv, freeze_frames.csv, features.csv
â”œâ”€â”€ models/ # trained model artifacts (e.g. xgboost_model.json)
â””â”€â”€ outputs/ # figures, SHAP values, logs, calibration plots

yaml
Copy
Edit

> _Note: `data/raw/` and `data/processed/` are excluded from version control (see `.gitignore`)._

---

## ğŸ”§ Setup & Installation

1. **Clone this repo**  
   ```bash
   git clone https://github.com/mobambas/xG-NextGen.git
   cd xG-NextGen
Create & activate a Python environment

bash
Copy
Edit
python3.9 -m venv venv
source venv/bin/activate
Install dependencies

bash
Copy
Edit
pip install --upgrade pip
pip install -r requirements.txt
Download StatsBomb Open Data
We leverage the free StatsBomb openâ€‘data repository for training and testing:
ğŸ”— https://github.com/statsbomb/open-data

Download the events/*.json and lineups/*.json files for your chosen competitions.

Place them under:

bash
Copy
Edit
data/raw/events/
data/raw/lineups/
Run Data Cleaning
Open and execute all cells in notebooks/01_data_cleaning.ipynb. This will:

Unzip & flatten raw JSON

Compute goal_difference, is_home, player positions

Export shots.csv & freeze_frames.csv to data/processed/

Engineer Features
Open and execute notebooks/02_feature_eng.ipynb. This will:

Load cleaned CSVs

Compute time, distance, angle, defensive pressure, assist type, preâ€‘shot sequence features

Oneâ€‘hot encode categoricals

Save features.csv to data/processed/

Train & Evaluate Models
Open and run notebooks/03_modeling.ipynb. This will:

Split features.csv into train/test

Train XGBoost (and benchmarks)

Evaluate AUCâ€‘ROC (~0.876), Brier score, log loss, calibration

Save best model to models/xgboost_model.json and SHAP outputs to outputs/

Launch the Streamlit Demo

bash
Copy
Edit
streamlit run app.py
Interactive mode: adjust the sidebar sliders for singleâ€‘shot predictions

Batch mode: upload a CSV of shotâ€‘level features (same columns as trained features)

ğŸŒŸ Key Results & Metrics
AUCâ€‘ROC: 0.876

Brier Score: 0.0686

Log Loss: 0.2361

Top SHAP Features:

goal_difference

angle

gk_distance

distance

minute

ğŸ¯ Project Goals
Reduce the gap between expected and actual goals.

Explain every prediction, showing why a chance is rated at a given probability.

Provide an openâ€‘source foundation for future xG research and operational use.

Join me in redefining what it means to measure a â€œgood chanceâ€ in the beautiful game.
Pull requests, issues, or feature ideas are warmly welcome!

makefile
Copy
Edit
::contentReference[oaicite:0]{index=0}







Sources
